{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZfXI01yCjCz"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain==0.0.147\n",
        "!pip install -q openai\n",
        "!pip install -q pypdf\n",
        "!pip install -q chromadb\n",
        "!pip install -q tiktoken\n",
        "!pip install -q aifactory\n",
        "!pip install -q faiss-cpu\n",
        "!pip install -q pypdf\n",
        "!pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRdpfI8bCjC3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import shutil\n",
        "import requests\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "# from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PDFMinerLoader\n",
        "from langchain.prompts import PromptTemplate, BaseChatPromptTemplate, StringPromptTemplate\n",
        "\n",
        "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain, ConversationalRetrievalChain, ChatVectorDBChain\n",
        "from langchain.agents import AgentExecutor, AgentType, Tool, ZeroShotAgent, initialize_agent, LLMSingleActionAgent, AgentOutputParser\n",
        "from typing import List, Union, Any, Optional\n",
        "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
        "from langchain import LLMChain\n",
        "import re\n",
        "import queue\n",
        "import threading\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.callbacks.base import CallbackManager\n",
        "from langchain.callbacks.tracers import LangChainTracer\n",
        "from langchain.memory import ConversationBufferWindowMemory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otY3jpzACjC3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"api-key\"\n",
        "\n",
        "TASK_ID = 2449\n",
        "TASK_KEY = \"35711198-94bd-4321-af54-e907c651d698\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me75QQQUCjC4"
      },
      "source": [
        "# Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXOpo51FCjC5"
      },
      "outputs": [],
      "source": [
        "# Streaming\n",
        "class ChainStreamHandler(StreamingStdOutCallbackHandler):\n",
        "    def __init__(self, gen):\n",
        "        super().__init__()\n",
        "        self.gen = gen\n",
        "\n",
        "    def on_llm_new_token(self, token: str, **kwargs: Any) -> Any:\n",
        "        self.gen.send(token)\n",
        "\n",
        "\n",
        "class ThreadedGenerator:\n",
        "    def __init__(self):\n",
        "        self.queue = queue.Queue()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        item = self.queue.get()\n",
        "        if item is StopIteration:\n",
        "            raise item\n",
        "        return item\n",
        "\n",
        "    def send(self, data):\n",
        "        self.queue.put(data)\n",
        "\n",
        "    def close(self):\n",
        "        self.queue.put(StopIteration)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPhmsTaHCjC6"
      },
      "outputs": [],
      "source": [
        "from googletrans import Translator\n",
        "def google_translate(text : str = None) -> str:\n",
        "    print(text)\n",
        "    translator = Translator()\n",
        "    result = translator.translate(text, dest=\"ko\")\n",
        "    return result.text\n",
        "\n",
        "# Tools\n",
        "\n",
        "def Node_check(text):\n",
        "    node_dict = {\n",
        "        \"서울\" : [\n",
        "            {\"node_id\" : 1,\n",
        "                \"run\" : \"ON\"},\n",
        "\n",
        "                {\"node_id\" : 2,\n",
        "                \"run\" : \"OFF\"},\n",
        "\n",
        "                {\"node_id\" : 3,\n",
        "                \"run\" : \"OFF\"}\n",
        "        ],\n",
        "\n",
        "        \"인천\" : [\n",
        "            {\"node_id\" : 1,\n",
        "                \"run\" : \"ON\"},\n",
        "\n",
        "                {\"node_id\" : 2,\n",
        "                \"run\" : \"OFF\"},\n",
        "        ],\n",
        "\n",
        "        \"대구\" : [\n",
        "            {\"node_id\" : 1,\n",
        "                \"run\" : \"ON\"},\n",
        "            \n",
        "\n",
        "        ],   \n",
        "    }\n",
        "\n",
        "    return node_dict\n",
        "\n",
        "\n",
        "def List_check(text):\n",
        "    return ['Node System', 'List System', 'State System']\n",
        "\n",
        "def State_check(text):\n",
        "    State_dict = {\n",
        "        \"서울\" : [\n",
        "            {\"state_id\" : 1,\n",
        "             \"state\" : 'NORMAL'},\n",
        "\n",
        "             {\"state_id\" : 2,\n",
        "              \"state\" : 'ABNORMAL'},\n",
        "\n",
        "              {\"state_id\" : 3,\n",
        "               \"state\" : 'NORMAL'}\n",
        "        ],\n",
        "\n",
        "        \"인천\" : [\n",
        "            {\"state_id\" : 1,\n",
        "             \"state\" : 'NORMAL'},\n",
        "\n",
        "             {\"state_id\" : 2,\n",
        "              \"state\" : 'ABNORMAL'},\n",
        "        ],\n",
        "\n",
        "        \"대구\" : [\n",
        "            {\"state_id\" : 1,\n",
        "             \"state\" : 'NORMAL'},\n",
        "\n",
        "\n",
        "        ],   \n",
        "    }\n",
        "    return State_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_tools(g):\n",
        "    if g == -1:\n",
        "        manager = None\n",
        "    else:\n",
        "        manager = CallbackManager([ChainStreamHandler(g)])\n",
        "\n",
        "\n",
        "    tools = []\n",
        "    \n",
        "    Node_tool = Tool(\n",
        "        name=\"Node System\",\n",
        "        func=Node_check,\n",
        "        description=\"시스템 노드에 대한 답변을 할때 사용합니다. \",\n",
        "        callback_manager=manager,\n",
        "        return_direct=False,\n",
        "    )\n",
        "    \n",
        "    List_tool = Tool(\n",
        "        name=\"List System\",\n",
        "        func=List_check,\n",
        "        description=\"사용가능한 도구 목록에 대한 답변을 할때 사용합니다.\",      \n",
        "        callback_manager=manager,\n",
        "        return_direct=False,\n",
        "    )\n",
        "    \n",
        "    State_tool = Tool(\n",
        "        name=\"State System\",\n",
        "        func=State_check,\n",
        "        description=\"시스템 상태 목록에 대한 답변을 할때 사용합니다.\",      \n",
        "        callback_manager=manager,\n",
        "        return_direct=False,\n",
        "    )\n",
        "\n",
        "\n",
        "    tools.append(Node_tool)\n",
        "    tools.append(List_tool)\n",
        "    tools.append(State_tool)\n",
        "\n",
        "    return tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQfcN_TqCjC6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_agent(g):\n",
        "    tools = get_tools(g)\n",
        "\n",
        "    PREFIX = \"\"\"\\n\\nHuman: You are KTChat, a large language model using Tools.\n",
        "You have access to the following tools.  Only one tool can be used for user questions.\n",
        "You MUST answer in Korean and in Markdown format:\"\"\"\n",
        "\n",
        "    SUFFIX = '''CHAT HISTORY: \"\"\"\n",
        "{chat_history}\n",
        "\"\"\"\n",
        "Question: \"\"\"\n",
        "{input}\n",
        "\"\"\"\n",
        "Thought: \"\"\"\n",
        "{agent_scratchpad}\n",
        "\"\"\"\n",
        "'''\n",
        "    \n",
        "    # manager = None\n",
        "    if g == -1:\n",
        "        manager = None\n",
        "    else:\n",
        "        manager = CallbackManager([ChainStreamHandler(g)])\n",
        "\n",
        "\n",
        "    streaming_llm = ChatOpenAI(\n",
        "        streaming=True,\n",
        "        verbose=True,\n",
        "        model_name=\"gpt-3.5-turbo\",\n",
        "        callback_manager=manager,\n",
        "        temperature=0.7,\n",
        "        # max_tokens=2048\n",
        "        )\n",
        "\n",
        "    agent_kwargs={\n",
        "        \"input_variables\": [\"input\", \"agent_scratchpad\", \"chat_history\"],\n",
        "        \"prefix\": PREFIX,\n",
        "        \"suffix\": SUFFIX,\n",
        "        }\n",
        "\n",
        "    agent = initialize_agent(tools, streaming_llm,\n",
        "                             agent=\"zero-shot-react-description\",\n",
        "                             max_iterations=3,\n",
        "                             callback_manager=manager,\n",
        "                             agent_kwargs=agent_kwargs,\n",
        "                             early_stopping_method=\"generate\"\n",
        "                             #  memory=memory,\n",
        "                             )\n",
        "\n",
        "    return agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olnMSnOyCjC7"
      },
      "outputs": [],
      "source": [
        "def run_chain(g, data):\n",
        "    try:\n",
        "        ag = get_agent(g)\n",
        "        ag(data)[\"output\"]\n",
        "    finally:\n",
        "        g.close()\n",
        "\n",
        "def chat(data):\n",
        "    g = ThreadedGenerator()\n",
        "    threading.Thread(target=run_chain, args=(g, data)).start()\n",
        "    return g\n",
        "\n",
        "def submit():\n",
        "    return chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RKcWV3tCjC8",
        "outputId": "fcafa50f-798c-422c-ee3c-84ba7a3ac0de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file : task-jvsc-dc682e52-3b3b-43c2-8b63-1d327033aa5829ae43f9-d862-4eaf-85e0-2415d9e2b98e\n",
            "jupyter notebook\n",
            "request id : 447 processing...\n",
            "score = 1g... \n"
          ]
        }
      ],
      "source": [
        "import aifactory.score as aif\n",
        "if __name__ == \"__main__\":\n",
        "    if os.path.isfile(\"aif.zip\"):\n",
        "        os.remove(\"aif.zip\")\n",
        "        \n",
        "    aif.submit(model_name=\"KT_chat\",\n",
        "               key=TASK_KEY,\n",
        "               func=submit\n",
        "               )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "choi",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3d9de1d24bc7cd8451fb0d53f98aed0100f78afcc7686cd98d0f7ac106da65ea"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}